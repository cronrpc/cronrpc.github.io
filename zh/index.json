[{"content":"Worley Noise Worley Noise1（也称为 Voronoi noise 和 Cellular noise）是由 Steven Worley2 在 1996 年引入的一种噪声函数。\n它的样子看起来就是生物细胞的样子，由一个个 cell 构成，作者本身也是叫它“Cellular Texture”。\nWorley Noise 的生成算法是：将整个图像分为一个个小方格，每个小方格中会有1个特征点，每个像素点的数值，是它到周围单元格中特征点的距离的最小值。\n由于每个小方格只有1个特征点，每个像素只需要检查临近的9个小方格，一共只需要对比9个点来计算出它的值。\n这里有2个在游戏中的应用案例3，分别是龟裂的干旱地面和造型夸张的烟柱。\nShadertoy 在本次代码实现过程中，我主要学习自Suboptimal Engineer4和The Book of Shaders5，并在Shadertoy6上进行了具体的代码编写。\n同时，在iquilezles7这个网站有很多图形学相关的知识可以进行参考。\nGrid Code 进入 Shadertoy，输入下列的代码：\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord ) { vec3 col = vec3(0.0); fragColor = vec4(col,1.0); } 此时显示纯黑色。\n将坐标变为正方形方格坐标，每个方格的范围在$[-0.5, +0.5]$之间。\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord ) { vec2 uv = fragCoord/iResolution.y; uv = uv * 4.0; vec2 gird = floor(uv); vec2 coord = fract(uv) - 0.5; vec3 col = vec3(coord, 0); fragColor = vec4(col,1.0); } 根据距离每个方格边框的距离，来进行上色。\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord ) { vec2 uv = fragCoord/iResolution.y; uv = uv * 4.0; vec2 gird = floor(uv); vec2 coord = fract(uv) - 0.5; float distanceGrid = 2.0 * max(abs(coord.x), abs(coord.y)); vec3 col = vec3(distanceGrid); fragColor = vec4(col,1.0); } 只在临近边界的地方进行上色，并添加颜色为红色。\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord ) { vec2 uv = fragCoord/iResolution.y; uv = uv * 4.0; vec2 gird = floor(uv); vec2 coord = fract(uv) - 0.5; float distanceGrid = smoothstep(0.9, 1.0, 2.0 * max(abs(coord.x), abs(coord.y))); vec3 girdColor = vec3(1.0, 0, 0) * vec3(distanceGrid); vec3 col = girdColor; fragColor = vec4(col,1.0); } Cell Code 接下来做两件事：\n根据伪随机函数，确定每个方格的点的位置 计算当前像素到临近9个方格点的距离，取最小值 先绘制所有方格点，每个方格中只有1个点。\nvec2 random2( vec2 p ) { // add 0.5 to avoid vec2(0, 0) return (0, 0) return fract(sin(vec2(dot(p + 0.5, vec2(213.1,322.2)),dot(p + 0.5, vec2(513.1,312.2))))*51312.1234); } void mainImage( out vec4 fragColor, in vec2 fragCoord ) { vec2 uv = fragCoord/iResolution.y; uv = uv * 4.0; vec2 gird = floor(uv); vec2 coord = fract(uv) - 0.5; // Gird Color float distanceGrid = smoothstep(0.9, 1.0, 2.0 * max(abs(coord.x), abs(coord.y))); vec3 girdColor = vec3(1.0, 0, 0) * vec3(distanceGrid); // Cell Color float distancePoint = 1.0; for (int i=-1; i\u0026lt;=1; i++) { for (int j=-1; j\u0026lt;=1; j++) { vec2 near = vec2(float(i), float(j)); vec2 point = near + 0.5 * sin(iTime + 6.2831 * random2(gird + near)); float currentDistance = length(coord - point); distancePoint = min(currentDistance, distancePoint); } } vec3 pointColor = vec3(smoothstep(0.90, 1.0, 1.0 - distancePoint)); vec3 col = girdColor + pointColor; fragColor = vec4(col,1.0); } 在有了距离后，只要根据距离显示颜色就可以了。\nvec2 random2( vec2 p ) { // add 0.5 to avoid vec2(0, 0) return (0, 0) return fract(sin(vec2(dot(p + 0.5, vec2(213.1,322.2)),dot(p + 0.5, vec2(513.1,312.2))))*51312.1234); } void mainImage( out vec4 fragColor, in vec2 fragCoord ) { vec2 uv = fragCoord/iResolution.y; uv = uv * 4.0; vec2 gird = floor(uv); vec2 coord = fract(uv) - 0.5; // Gird Color float distanceGrid = smoothstep(0.95, 1.0, 2.0 * max(abs(coord.x), abs(coord.y))); vec3 girdColor = vec3(1.0, 0, 0) * vec3(distanceGrid); // Cell Color float distancePoint = 1.0; for (int i=-1; i\u0026lt;=1; i++) { for (int j=-1; j\u0026lt;=1; j++) { vec2 near = vec2(float(i), float(j)); vec2 point = near + 0.5 * sin(iTime + 6.2831 * random2(gird + near)); float currentDistance = length(coord - point); distancePoint = min(currentDistance, distancePoint); } } vec3 pointColor = vec3(smoothstep(0.95, 1.0, 1.0 - distancePoint)); vec3 distanceColor = vec3(smoothstep(0.2, 2.0, 1.7 - distancePoint)); vec3 col = girdColor + pointColor + distanceColor; fragColor = vec4(col,1.0); } 最后，如果移除辅助网格和中点，得到 Worley Noise 的图像。\nPalettes 最后通过渐变插值来上一点颜色8\nvec3 palette( in float t) { vec3 a = vec3(0.5, 0.5, 0.5); vec3 b = vec3(0.5, 0.5, 0.5); vec3 c = vec3(1.0, 1.0, 1.0); vec3 d = vec3(0.0, 0.1, 0.2); return a + b * cos( 6.283185 * ( c * t + d ) ); } vec2 random2( vec2 p ) { // add 0.5 to avoid vec2(0, 0) return (0, 0) return fract(sin(vec2(dot(p + 0.5, vec2(213.1,322.2)),dot(p + 0.5, vec2(513.1,312.2))))*51312.1234); } void mainImage( out vec4 fragColor, in vec2 fragCoord ) { vec2 uv = fragCoord/iResolution.y; uv = uv * 4.0; vec2 gird = floor(uv); vec2 coord = fract(uv) - 0.5; // Gird Color float distanceGrid = smoothstep(0.95, 1.0, 2.0 * max(abs(coord.x), abs(coord.y))); vec3 girdColor = vec3(1.0, 0, 0) * vec3(distanceGrid); // Cell Color float distancePoint = 1.0; for (int i=-1; i\u0026lt;=1; i++) { for (int j=-1; j\u0026lt;=1; j++) { vec2 near = vec2(float(i), float(j)); vec2 point = near + 0.5 * sin(iTime + 6.2831 * random2(gird + near)); float currentDistance = length(coord - point); distancePoint = min(currentDistance, distancePoint); } } vec3 pointColor = vec3(smoothstep(0.95, 1.0, 1.0 - distancePoint)); vec3 distanceColor = vec3(palette(smoothstep(0.2, 2.0, 1.7 - distancePoint))); vec3 col = distanceColor; col += girdColor + pointColor; fragColor = vec4(col,1.0); } wikipedia, Worley noise, https://en.wikipedia.org/wiki/Worley_noise\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSteven Worley, (1996), A Cellular Texture Basis Function, https://cedric.cnam.fr/~cubaud/PROCEDURAL/worley.pdf\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPor Ryan Brucks, (2016) , Getting the Most Out of Noise in UE4, https://www.unrealengine.com/es-ES/tech-blog/getting-the-most-out-of-noise-in-ue4\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSuboptimal Engineer, (2023), What is Voronoi Noise? , https://www.youtube.com/watch?v=vcfIJ5Uu6Qw\u0026ab_channel=SuboptimalEngineer\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPatricio Gonzalez Vivo and Jen Lowe, The Book of Shaders, https://thebookofshaders.com/12/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nShadertoy, https://www.shadertoy.com/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\niquilezles, float small and random, https://iquilezles.org/articles/sfrand/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\niquilezles, palettes - 1999, https://iquilezles.org/articles/palettes/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://cronrpc.github.io/zh/posts/worley-noise-generator/","summary":"\u003ch2 id=\"worley-noise\"\u003eWorley Noise\u003c/h2\u003e\n\u003cp\u003eWorley Noise\u003csup id=\"fnref:1\"\u003e\u003ca href=\"#fn:1\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e1\u003c/a\u003e\u003c/sup\u003e（也称为 Voronoi noise 和 Cellular noise）是由 Steven Worley\u003csup id=\"fnref:2\"\u003e\u003ca href=\"#fn:2\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e2\u003c/a\u003e\u003c/sup\u003e 在 1996 年引入的一种噪声函数。\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"worley noise\" loading=\"lazy\" src=\"/zh/posts/worley-noise-generator/worley-noise.png\"\u003e\u003c/p\u003e\n\u003cp\u003e它的样子看起来就是生物细胞的样子，由一个个 cell 构成，作者本身也是叫它“Cellular Texture”。\u003c/p\u003e","title":"Worley Noise / Voronoi Noise Generator"},{"content":"SDF 介绍 Signed Distance Field (SDF) Signed Distance Field（有符号距离场）1是一种用于表示形状的数学函数或数据结构。\n它在二维或三维空间中为每个点分配一个带符号的距离值，表示该点到最近表面（或边界）的距离，并用符号区分内外：\n正值：点位于形状外部，数值表示距离表面的最近距离。 负值：点位于形状内部，绝对值表示距离表面的最近距离。 零：点正好位于形状的表面上。 形式化定义，对于空间中的点 $x$，SDF 可以表示为：\n$$ f(x) = \\begin{cases} d(x, \\partial\\Omega), \u0026amp; \\text{if } x \\in \\Omega \\\\ -d(x, \\partial\\Omega), \u0026amp; \\text{if } x \\notin \\Omega \\\\ 0, \u0026amp; \\text{if } x \\in \\partial\\Omega \\end{cases} $$\n其中的$\\Omega$属于物体内，$\\partial\\Omega$表示边界，$d(x, \\partial\\Omega)$表示点$x$到边界的最小距离。\nGitHub 仓库 如果你想查看最终的生成SDF图片的代码，可以在GitHub仓库2获取：cronrpc/Signed-Distance-Field-2D-Generator\n应用 上面的说法可能非常抽象，我们看一些具体的应用实例。\n字体渲染（Valve 的 SDF 字体技术3），Unity的TMP字体就是使用了SDF技术。 光线追踪中的表面求交\n风格化阴影、云等\n凡是某种连续过渡的参数，都可以考虑使用SDF技术。\n2D SDF 生成算法 对于一张灰度图，白色部分表示物体，黑色是背景。如何生成它的SDF图呢？\n暴力求值法 一个最为简单的方式是，遍历算法。\n首先我们找出所有的边界集合。也就是当前像素是白色，而周围像素有黑色的点。 遍历所有的点，计算距离边界集合的最近距离。 根据本身的黑白，添加距离的正负号。 如果假设像素点的数目是$n$，那么复杂度是$O(n^2)$。\n# generator_sdf.py import sys import math from PIL import Image import numpy as np def generate_sdf(input_path, output_path): # 读取灰度图（0-255） img = Image.open(input_path).convert(\u0026#34;L\u0026#34;) w, h = img.size pixels = np.array(img) # Step 1: 找出边界集合 boundary_points = [] for y in range(h): for x in range(w): if pixels[y, x] \u0026gt; 127: # 白色 # 检查周围像素是否有黑色 neighbors = [ (nx, ny) for nx in (x - 1, x, x + 1) for ny in (y - 1, y, y + 1) if 0 \u0026lt;= nx \u0026lt; w and 0 \u0026lt;= ny \u0026lt; h and not (nx == x and ny == y) ] for nx, ny in neighbors: if pixels[ny, nx] \u0026lt;= 127: # 黑色 boundary_points.append((x, y)) break # Step 2 \u0026amp; 3: 计算SDF sdf = np.zeros((h, w), dtype=np.float32) for y in range(h): for x in range(w): min_dist = float(\u0026#34;inf\u0026#34;) for bx, by in boundary_points: dist = math.sqrt((x - bx) ** 2 + (y - by) ** 2) if dist \u0026lt; min_dist: min_dist = dist # 黑色取负值 if pixels[y, x] \u0026lt;= 127: min_dist = -min_dist sdf[y, x] = min_dist # 归一化到0-255 max_dist = np.max(np.abs(sdf)) sdf_normalized = ((sdf / max_dist) + 1) * 127.5 sdf_img = Image.fromarray(np.clip(sdf_normalized, 0, 255).astype(np.uint8)) sdf_img.save(output_path) print(f\u0026#34;SDF saved to {output_path}\u0026#34;) if __name__ == \u0026#34;__main__\u0026#34;: if len(sys.argv) != 3: print(\u0026#34;Example: python generator_sdf.py test.png test_sdf.png\u0026#34;) sys.exit(1) generate_sdf(sys.argv[1], sys.argv[2]) 生成的结果：\n通过在PS中改变图片的显示阈值，可以观察到圆形的SDF变化：\n同理在正方形的SDF中，也可以观察效果。正方形的SDF的特点就是在内部时等高线是直角，在外部时等高线是圆弧。\n八邻域欧几里得近似距离 度量空间4（Metric Space）是数学中刻画“距离”这一概念的抽象框架。它由一个集合 $X$ 及其上的距离函数\n$$ d : X \\times X \\to \\mathbb{R} $$\n构成，并且这个距离函数必须满足以下四个条件：\n非负性：距离永远是非负数。\n恒等性：距离为零时，两点必须相同。\n对称性：从 $x$ 到 $y$ 的距离等于从 $y$ 到 $x$ 的距离。\n三角不等式：直接到达不应比绕路更远。\n$$ d(x, z) \\le d(x, y) + d(y, z) $$\n例如，在连续的二维平面中，欧几里得距离：\n$$ d(P, Q) = \\sqrt{(x_P - x_Q)^2 + (y_P - y_Q)^2} $$\n是一个典型的度量函数。\n下图的蓝色线条、红色线条、黄色线条都是表示同样的长度，而绿色是比它们都短的欧几里得距离。\n然而在数字图像处理或栅格地图中，我们的点是离散的像素格，距离计算可以直接用欧几里得公式，但这样需要大量平方根运算，代价较高。 为提高效率，常采用 八邻域欧几里得近似距离（8-neighborhood Euclidean approximation）：\n八邻域：指每个像素与其水平方向、垂直方向和对角线方向上最近的 8 个像素相邻。 在这种邻接关系下，可以用下式近似欧几里得距离： $$ d_{8}(p, q) \\approx \\max(\\Delta x, \\Delta y) + (\\sqrt{2} - 1) \\cdot \\min(\\Delta x, \\Delta y) $$\n其中 $\\Delta x = |x_p - x_q|$，$\\Delta y = |y_p - y_q|$。\n例如下图中的红色就是表示八邻域欧几里得近似距离，而蓝色直线就是欧几里得距离。\n这种方法避免了大量开方计算，同时在 8 邻域范围内与真实欧几里得距离的误差很小，因此常用于路径搜索（A*、Dijkstra）、距离变换、图像形态学等场景。\n8SSEDT 对这个算法的介绍参考自Lisapple 8SSEDT5。\n在上一小节中，我们已经介绍了八邻域欧几里得近似距离。实际上，对于图中的每个节点，其距离值可以用如下递推关系表示：\n$$ f(x, y) = \\min_{\\substack{dx, dy \\in {-1,0,1} \\ (dx, dy) \\neq (0,0)}} \\Big( f(x+dx, y+dy) + d(dx, dy) \\Big) $$\n其中，$d(dx, dy)$ 表示从邻居节点 $(x+dx, y+dy)$ 移动到节点 $(x, y)$ 的代价，通常取：\n$$ d(dx, dy) = \\begin{cases} 1, \u0026amp; \\text{若 } |dx| + |dy| = 1 \\quad (\\text{水平或垂直邻居})\\\\ \\sqrt{2}, \u0026amp; \\text{若 } |dx| + |dy| = 2 \\quad (\\text{对角邻居}) \\end{cases} $$\n这里，$dx$ 和 $dy$ 可以分别取 $-1, 0, 1$，但不能同时为零，这样才是邻居节点。\n如果给邻居节点进行标号：\n[#1][#2][#3] [#4][ x][#5] [#6][#7][#8] 对于任意两个点$x$和$y$之间的距离路径，只可能由下面4个组合中的1种构成，也就是说必然是其中之一的线性叠加：\n1,2,4 2,3,5 4,6,7 5,7,8 所以从左上角递推到右下角，就可以覆盖第1种$1,2,4$的可能，也就是说最多$4$次遍历整个图，就能确定所有点的值。\n当然，这里进行了一点优化，参考Signed Distance Fields6的实现，他选择了下列$4$个遍历路径：\n- - - \u0026gt; | [?][?][?] | [?][x][ ] v [ ][ ][ ] \u0026lt; - - - | [ ][ ][ ] | [ ][x][?] v [ ][ ][ ] \u0026lt; - - - ^ [ ][ ][ ] | [ ][x][?] | [?][?][?] - - - \u0026gt; ^ [ ][ ][ ] | [?][x][ ] | [ ][ ][ ] 这里直接给出Python的实现：\n准确来说下列代码的距离定义是欧几里得距离，并不是八邻域欧几里得近似距离。 只是借鉴了移动方向为8个方向 import sys import os import numpy as np from PIL import Image INF = 9999 def dist_sq(dx, dy): return dx*dx + dy*dy def compare(grid, p, x, y, ox, oy, width, height): nx = x + ox ny = y + oy if 0 \u0026lt;= nx \u0026lt; width and 0 \u0026lt;= ny \u0026lt; height: other_dx, other_dy = grid[ny, nx] else: other_dx, other_dy = INF, INF other_dx += ox other_dy += oy if dist_sq(other_dx, other_dy) \u0026lt; dist_sq(*p): p = (other_dx, other_dy) return p def generate_sdf(grid): height, width, _ = grid.shape # Pass 0 for y in range(height): for x in range(width): p = tuple(grid[y, x]) p = compare(grid, p, x, y, -1, 0, width, height) p = compare(grid, p, x, y, 0, -1, width, height) p = compare(grid, p, x, y, -1, -1, width, height) p = compare(grid, p, x, y, 1, -1, width, height) grid[y, x] = p for x in range(width-1, -1, -1): p = tuple(grid[y, x]) p = compare(grid, p, x, y, 1, 0, width, height) grid[y, x] = p # Pass 1 for y in range(height-1, -1, -1): for x in range(width-1, -1, -1): p = tuple(grid[y, x]) p = compare(grid, p, x, y, 1, 0, width, height) p = compare(grid, p, x, y, 0, 1, width, height) p = compare(grid, p, x, y, -1, 1, width, height) p = compare(grid, p, x, y, 1, 1, width, height) grid[y, x] = p for x in range(width): p = tuple(grid[y, x]) p = compare(grid, p, x, y, -1, 0, width, height) grid[y, x] = p def load_image_binary(path, threshold=128): im = Image.open(path).convert(\u0026#39;L\u0026#39;) arr = np.array(im, dtype=np.uint8) inside = arr \u0026lt; threshold return inside, im def save_signed_sdf_image(signed, out_path): # 归一化到0-255，128为边界 max_dist = np.max(np.abs(signed)) if max_dist == 0: # 防止除以0 sdf_normalized = np.full_like(signed, 128.0) else: sdf_normalized = ((signed / max_dist) + 1.0) * 128.0 sdf_normalized = np.clip(sdf_normalized, 0, 255).astype(np.uint8) out = Image.fromarray(sdf_normalized, mode=\u0026#39;L\u0026#39;) out.save(out_path) def main(): if len(sys.argv) \u0026lt; 2: print(\u0026#34;Usage: python 8ssedt.py input.png\u0026#34;) sys.exit(1) in_path = sys.argv[1] if not os.path.exists(in_path): print(\u0026#34;File not found:\u0026#34;, in_path) sys.exit(1) inside, im = load_image_binary(in_path) h, w = inside.shape empty = (INF, INF) zero = (0, 0) # two grids: inside distances and outside distances grid1 = np.zeros((h, w, 2), dtype=int) grid2 = np.zeros((h, w, 2), dtype=int) for y in range(h): for x in range(w): if inside[y, x]: grid1[y, x] = zero grid2[y, x] = empty else: grid1[y, x] = empty grid2[y, x] = zero generate_sdf(grid1) generate_sdf(grid2) dist1 = np.sqrt(grid1[:, :, 0]**2 + grid1[:, :, 1]**2) dist2 = np.sqrt(grid2[:, :, 0]**2 + grid2[:, :, 1]**2) signed = dist1 - dist2 base, ext = os.path.splitext(in_path) out_path = base + \u0026#34;_8ssedt.png\u0026#34; save_signed_sdf_image(signed, out_path) print(\u0026#34;Saved:\u0026#34;, out_path) if __name__ == \u0026#34;__main__\u0026#34;: main() 我们用它实验的这张原图来看看效果：\n在运行我们的脚本后，得到：\n放入PS中，查看不同阈值下的效果：\nCorrect 8SSEDT 参考7，他解决的问题是，对于2值的黑白图来说，邻近边界的点，距离边界的距离实质上应该只有半个像素。\n考虑到这半个像素的差别，会导致在接近边界的地方有一些误差，解决方法就是旁边的点是边界的时候，距离就只加一半的大小。\nimport sys import os import math import numpy as np from PIL import Image FIX = True INF = 9999 def dist_sq(dx, dy): return dx*dx + dy*dy def compare(grid, p, x, y, ox, oy, width, height): nx = x + ox ny = y + oy if 0 \u0026lt;= nx \u0026lt; width and 0 \u0026lt;= ny \u0026lt; height: other_dx, other_dy = grid[ny, nx] else: other_dx, other_dy = INF, INF if FIX: if other_dx != 0 or other_dy != 0: # 对应 other.DistSq()!=0 ox *= 2 oy *= 2 other_dx += ox other_dy += oy if dist_sq(other_dx, other_dy) \u0026lt; dist_sq(*p): p = (other_dx, other_dy) return p def generate_sdf(grid): height, width, _ = grid.shape # Pass 0 for y in range(height): for x in range(width): p = tuple(grid[y, x]) p = compare(grid, p, x, y, -1, 0, width, height) p = compare(grid, p, x, y, 0, -1, width, height) p = compare(grid, p, x, y, -1, -1, width, height) p = compare(grid, p, x, y, 1, -1, width, height) grid[y, x] = p for x in range(width-1, -1, -1): p = tuple(grid[y, x]) p = compare(grid, p, x, y, 1, 0, width, height) grid[y, x] = p # Pass 1 for y in range(height-1, -1, -1): for x in range(width-1, -1, -1): p = tuple(grid[y, x]) p = compare(grid, p, x, y, 1, 0, width, height) p = compare(grid, p, x, y, 0, 1, width, height) p = compare(grid, p, x, y, -1, 1, width, height) p = compare(grid, p, x, y, 1, 1, width, height) grid[y, x] = p for x in range(width): p = tuple(grid[y, x]) p = compare(grid, p, x, y, -1, 0, width, height) grid[y, x] = p def load_image_binary(path, threshold=128): im = Image.open(path).convert(\u0026#39;L\u0026#39;) arr = np.array(im, dtype=np.uint8) inside = arr \u0026lt; threshold return inside, im def save_signed_sdf_image(signed, out_path): # 归一化到0-255，128为边界 max_dist = np.max(np.abs(signed)) if max_dist == 0: # 防止除以0 sdf_normalized = np.full_like(signed, 128.0) else: sdf_normalized = ((signed / max_dist) + 1.0) * 128.0 sdf_normalized = np.clip(sdf_normalized, 0, 255).astype(np.uint8) out = Image.fromarray(sdf_normalized, mode=\u0026#39;L\u0026#39;) out.save(out_path) def main(): if len(sys.argv) \u0026lt; 2: print(\u0026#34;Usage: python 8ssedt.py input.png\u0026#34;) sys.exit(1) in_path = sys.argv[1] if not os.path.exists(in_path): print(\u0026#34;File not found:\u0026#34;, in_path) sys.exit(1) inside, im = load_image_binary(in_path) h, w = inside.shape empty = (INF, INF) zero = (0, 0) # two grids: inside distances and outside distances grid1 = np.zeros((h, w, 2), dtype=int) grid2 = np.zeros((h, w, 2), dtype=int) for y in range(h): for x in range(w): if inside[y, x]: grid1[y, x] = zero grid2[y, x] = empty else: grid1[y, x] = empty grid2[y, x] = zero generate_sdf(grid1) generate_sdf(grid2) dist1 = np.sqrt(grid1[:, :, 0]**2 + grid1[:, :, 1]**2) dist2 = np.sqrt(grid2[:, :, 0]**2 + grid2[:, :, 1]**2) if FIX: signed = 0.5 * (dist1 - dist2) else: signed = dist1 - dist2 base, ext = os.path.splitext(in_path) out_path = base + \u0026#34;_8ssedt_correct.png\u0026#34; save_signed_sdf_image(signed, out_path) print(\u0026#34;Saved:\u0026#34;, out_path) if __name__ == \u0026#34;__main__\u0026#34;: main() 从效果上看，几乎是和之前一样：\n但是从阈值角度来看，会稍微平滑一些，观察接近地方的值就知道了。\n修正后的结果：\n原来的结果：\n为什么还是用欧几里得距离？ 用公式：\n$$ d_8(p,q) = \\max(\\Delta x,\\Delta y) + (\\sqrt{2} - 1) \\cdot \\min(\\Delta x,\\Delta y) $$\n如果取两个点：$(1,4)$ 和 $(3,3)$\n计算 $d_8$\n$d_8(1,4) = 4 + (\\sqrt{2} - 1) \\cdot 1 \\approx 4 + 0.4142 = 4.4142$\n$d_8(3,3) = 3 + (\\sqrt{2} - 1) \\cdot 3 \\approx 3 + 1.2426 = 4.2426$\n⇒ $d_8(1,4) \u0026gt; d_8(3,3)$\n计算欧几里得距离\n$d_E(1,4) = \\sqrt{1^2 + 4^2} = \\sqrt{17} \\approx 4.1231$\n$d_E(3,3) = \\sqrt{3^2 + 3^2} = \\sqrt{18} \\approx 4.2426$\n⇒ $d_E(1,4) \u0026lt; d_E(3,3)$\n这个反例说明：$d_8$ 的排序不一定和欧几里得距离的排序一致，因此这里只是借鉴了八邻域的位移，但是两个点之间的距离还是按照欧几里得距离来计算。\nscipy.ndimage 库 前面用到的算法用Python写的还是太慢了，尤其是循环嵌套，在2048x2048开始速度会比较慢。\nscipy的图像处理底层采用C++来编写，速度会快非常多。\n下面代码的scale采用8（后面会说为什么不要使用normalize，而是用固定比例的缩放），同时输出采用16bit（而不是8bit）的灰度图。\nimport sys import os import numpy as np from PIL import Image from scipy import ndimage scale = 8 def load_image_binary(path, threshold=128): im = Image.open(path).convert(\u0026#39;L\u0026#39;) arr = np.array(im, dtype=np.uint8) inside = arr \u0026lt; threshold return inside def save_sdf_16bit(signed, out_path): # 直接转 uint16 保存，不做归一化 signed = signed * scale + 32767.5 signed_uint16 = np.clip(signed, 0, 65535).astype(np.uint16) out = Image.fromarray(signed_uint16, mode=\u0026#39;I;16\u0026#39;) out.save(out_path) def fast_signed_sdf(mask): dist_inside = ndimage.distance_transform_edt(mask) dist_outside = ndimage.distance_transform_edt(~mask) return dist_outside - dist_inside # inside 正，outside 负 def main(): if len(sys.argv) \u0026lt; 2: print(\u0026#34;Usage: python fast_sdf.py input1.png [input2.png ...]\u0026#34;) sys.exit(1) for in_path in sys.argv[1:]: if not os.path.exists(in_path): print(\u0026#34;File not found:\u0026#34;, in_path) continue inside = load_image_binary(in_path) signed = fast_signed_sdf(inside) base, _ = os.path.splitext(in_path) out_path = base + \u0026#34;_sdf16.png\u0026#34; save_sdf_16bit(signed, out_path) print(f\u0026#34;Saved SDF to {out_path}\u0026#34;) if __name__ == \u0026#34;__main__\u0026#34;: main() 16bit 和 scale 前面使用了归一化距离的方式，但是如果希望合成多张图片，需要将距离的单位统一（因为需要在两张图片之间进行插值）。\n第二，如果图片尺寸非常大（2048），那么8bit只有256大小，就不够表示所有距离了，为了避免距离截断导致效果不好，采用16bit的png来存储距离。\n2048x2048大小的图片，两点间的最大距离是$2048*1.414=2,896$，同时16bit可以表示的最大范围是+-32767，所以可以选择$scale=8$或者$10$来表示。\nscale = 10 # 缩放到 0–65535，32767.5 为边界 unsigned = signed * scale + 32767.5 unsigned = np.clip(unsigned, 0, 65535).astype(np.uint16) 合成算法 怎么合成图片，取决于我们到底想实现什么样的效果。\n比如如果是想实现一个 subtraction 的效果，是不是直接把距离做减法就可以了呢？\n这种做法确实可以实现在中点处表现为减法，但是最左侧和左右侧的含义实际上是不明确的。\n# 布尔运算 def sdf_union(d1, d2): return np.minimum(d1, d2) # 并集 def sdf_intersection(d1, d2): return np.maximum(d1, d2) # 交集 def sdf_subtraction(d1, d2): return np.maximum(d1, -d2) # A 减 B 类似上面代码的合并的实际含义是：当处在阈值中点的时候，表现为并、交或者减法。\n插值思路 在游戏中，实质上追求的是这样一个过程，假如有两张图片a和b，我们希望在阈值最大的时候图片就是a的图案，阈值最小的时候图片就是b的图案。\n如果是三张图片，那就是最大值是a的图案，中间时就是b的图案，最小值时就是c的图案，以此类推。\n这里还需要限制一个条件，那就是它们必须是完全包含的关系，也就是$c \\supset b \\supset a$，只有这样才可能实现这个过程。\n对于图片a和b，由于包含关系，物体a上的任意一个像素，在a和b中的距离值都应该是正数，也就是在物体内部。\n对于$b-a$上的一个点$x$，在a中一定是负数$x_a$（外侧），在b中是正数$x_b$。所以$x$这个点在最终图像上的值$x_{final}$，实际上就应该是$x$从$x_b$插值到$x_a$过程中，$x=0$时刻对应的阈值的大小。\n比如，如果$x$在${sdf}_a$的值是$-3$，在${sdf}_b$的值是$3$。\n那么${x}_{final}$的大小在8bit灰度图下就应该是128，这样刚好在阈值128以下都能点亮这个像素。\n所以，核心的思路就是找对应的0点。\n蒙特卡洛插值法 这里参考了这篇文章8的算法，通过采样方式来寻找0点。\n注意，在Python下这种嵌套循环运行速度是非常慢的，超过2048尺寸的图片不适合用纯Python来写。\nimport sys import numpy as np from PIL import Image if len(sys.argv) != 3: print(\u0026#34;用法: python compose2.py a.png b.png\u0026#34;) sys.exit(1) # 读取 16bit 灰度图 def load_16bit_gray(path): img = Image.open(path) arr = np.array(img, dtype=np.uint16) return arr sdf1 = load_16bit_gray(sys.argv[1]) sdf2 = load_16bit_gray(sys.argv[2]) # 检查尺寸一致 if sdf1.shape != sdf2.shape: raise ValueError(\u0026#34;两张输入图片的尺寸必须相同\u0026#34;) height, width = sdf1.shape output = np.zeros((height, width), dtype=np.uint16) THRESHOLD = 32768 # 16bit 对应 0.5 灰度 MAX_VAL = 65535 STEPS = 16 for y in range(height): for x in range(width): t1 = sdf1[y, x] t2 = sdf2[y, x] if t1 \u0026lt; THRESHOLD and t2 \u0026lt; THRESHOLD: result = 0 elif t1 \u0026gt; THRESHOLD and t2 \u0026gt; THRESHOLD: result = MAX_VAL else: # 两张图片之间插值 result = 0 for i in range(STEPS): weight = i / STEPS interp = (1 - weight) * t1 + weight * t2 result += 0 if interp \u0026lt; THRESHOLD else MAX_VAL result //= STEPS output[y, x] = np.clip(result, 0, MAX_VAL) # 保存 16bit PNG out_img = Image.fromarray(output, mode=\u0026#39;I;16\u0026#39;) out_img.save(\u0026#34;output.png\u0026#34;) print(\u0026#34;合成完成: output.png\u0026#34;) 最终的算法 插值这个过程完全可以并行处理，首先每个像素之间就毫无关联，其次每个图片之间进行插值其实也没有关联。\n使用numpy来进行并行化处理，numpy底层是c++模块，速度非常快。\n这里采样点为256个对应灰度图范围，保存为8bit的灰度图（这里没必要16bit）。\nimport sys import numpy as np from PIL import Image U8 = True if len(sys.argv) \u0026lt; 3: print(\u0026#34;用法: python compose.py img1.png img2.png [img3.png ...]\u0026#34;) sys.exit(1) def load_16bit_gray(path): img = Image.open(path) arr = np.array(img, dtype=np.uint16) return arr # 读取所有图 images = [load_16bit_gray(path) for path in sys.argv[1:]] arr = np.stack(images, axis=0) # shape: (N, H, W) if not np.all([img.shape == arr[0].shape for img in images]): raise ValueError(\u0026#34;所有输入图片的尺寸必须相同\u0026#34;) THRESHOLD = 32768 MAX_VAL = 65535 N, H, W = arr.shape # 全局 mask all_below = np.all(arr \u0026lt; THRESHOLD, axis=0) all_above = np.all(arr \u0026gt; THRESHOLD, axis=0) output = np.zeros((H, W), dtype=np.float64) output[all_below] = 0 output[all_above] = MAX_VAL # 混合部分 mask mix_mask = ~(all_below | all_above) # 取混合部分像素 mix_pixels = arr[:, mix_mask].astype(np.float64) # shape: (N, M) M = 混合像素个数 M = mix_pixels.shape[1] # 256 个采样权重 samples = 256 weights = np.linspace(0, 1, samples, endpoint=False) # 每个采样点属于哪两个图之间 intervals = np.floor(weights * (N - 1)).astype(int) # shape: (samples,) local_w = (weights * (N - 1)) - intervals # shape: (samples,) # 插值批量计算 interp_results = np.zeros((samples, M), dtype=np.float64) for k in range(samples): i1 = intervals[k] i2 = i1 + 1 val = (1 - local_w[k]) * mix_pixels[i1] + local_w[k] * mix_pixels[i2] interp_results[k] = (val \u0026gt;= THRESHOLD) * MAX_VAL # 平均 res = np.mean(interp_results, axis=0) # 回写结果 output[mix_mask] = res if U8: # 转为浮点数，映射到 0~255 output_float = output.astype(np.float32) output_scaled = output_float / 65535.0 * 255.0 output_uint8 = np.clip(np.floor(output_scaled + 0.5), 0, 255).astype(np.uint8) # 保存 8 位灰度图 out_img = Image.fromarray(output_uint8, mode=\u0026#39;L\u0026#39;) out_img.save(\u0026#34;output8.png\u0026#34;) print(f\u0026#34;合成完成: output8.png，合并了 {N} 张图片\u0026#34;) else: output = np.clip(output, 0, MAX_VAL).astype(np.uint16) out_img = Image.fromarray(output, mode=\u0026#39;I;16\u0026#39;) out_img.save(\u0026#34;output16.png\u0026#34;) print(f\u0026#34;合成完成: output16.png，合并了 {N} 张图片\u0026#34;) 效果：\n原始图片：\n生成的sdf如图，这里因为scale的关系，看起来都比较接近灰色。\n合成sdf：\nwikipedia, Signed distance function, https://en.wikipedia.org/wiki/Signed_distance_function\u0026#160;\u0026#x21a9;\u0026#xfe0e;\ncronrpc, (2025), Signed Distance Field 2D Generator, https://github.com/cronrpc/Signed-Distance-Field-2D-Generator\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nChris Green. Valve. (2007). Improved Alpha-Tested Magnification for Vector Textures and Special Effects, https://steamcdn-a.akamaihd.net/apps/valve/2007/SIGGRAPH2007_AlphaTestedMagnification.pdf\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMetric Space, https://en.wikipedia.org/wiki/Metric_space\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nLisapple, (2017), 8SSEDT , GitHub, https://github.com/Lisapple/8SSEDT\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nRichard Mitton, (2009), Signed Distance Fields, http://www.codersnotes.com/notes/signed-distance-fields/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nfarteryhr, Correct 8SSEDT, https://replit.com/@farteryhr/Correct8SSEDT#main.cpp\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n蛋白胨, Unity 卡通渲染 程序化天空盒, https://zhuanlan.zhihu.com/p/540692272\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://cronrpc.github.io/zh/posts/signed-distance-field/","summary":"\u003ch2 id=\"sdf-介绍\"\u003eSDF 介绍\u003c/h2\u003e\n\u003ch3 id=\"signed-distance-field-sdf\"\u003eSigned Distance Field (SDF)\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eSigned Distance Field\u003c/strong\u003e（有符号距离场）\u003csup id=\"fnref:1\"\u003e\u003ca href=\"#fn:1\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e1\u003c/a\u003e\u003c/sup\u003e是一种用于表示形状的数学函数或数据结构。\u003cbr\u003e\n它在二维或三维空间中为每个点分配一个\u003cstrong\u003e带符号的距离值\u003c/strong\u003e，表示该点到最近表面（或边界）的距离，并用符号区分内外：\u003c/p\u003e","title":"有符号距离场(SDF)"},{"content":"Perlin Noise 介绍 Perlin 噪声（Perlin Noise）是由 Ken Perlin 在 1983 年为电影《Tron》开发的一种平滑伪随机噪声算法1。它能够生成具有自然纹理的随机模式，广泛用于计算机图形学中模拟云彩、地形、火焰、木纹、水流等自然现象2。\n与普通白噪声不同，Perlin 噪声具有空间相关性：相邻采样点的值变化平滑，没有突兀的跳变。这种平滑特性使得它生成的纹理更像自然界的连续变化。\n我的世界就采用 Perlin Noise 来作为生成无限世界地图的基础算法。\n噪声类型 1D 均匀白噪声 1D 均匀白噪声 就是一维的、服从均匀分布的白噪声信号。\nimport numpy as np import matplotlib.pyplot as plt def sample_random_points(num_points): # 采样器函数，返回num_points个0~1之间的随机数 return np.random.rand(num_points) def draw_random_strip_image_from_samples(rand_1d, width, height, filename, thickness=1): num_points = len(rand_1d) cols_per_point = width // num_points rand_pos = (rand_1d * (height - 1)).astype(int) img = np.zeros((height, width)) for i, row in enumerate(rand_pos): start_row = max(row - thickness, 0) end_row = min(row + thickness + 1, height) start_col = i * cols_per_point end_col = start_col + cols_per_point img[start_row:end_row, start_col:end_col] = 1 plt.imshow(img, cmap=\u0026#39;gray\u0026#39;, origin=\u0026#39;lower\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.show() plt.imsave(filename, img, cmap=\u0026#39;gray\u0026#39;) if __name__ == \u0026#34;__main__\u0026#34;: rand_noise = sample_random_points(512) draw_random_strip_image_from_samples(rand_noise, 1024, 512, \u0026#34;random_noise_1d.png\u0026#34;) 对于一维随机噪声来说，生成的随机点之间是没有任何关联的。\n如果采用Perlin Noise，得到的是连续而光滑的曲线。\n2D 均匀白噪声 如果我们随机生成一张均匀分布的噪声图，结果就是均匀白噪声，它们每个点和相邻的点之间是没有任何联系的。\nimport numpy as np import matplotlib.pyplot as plt # 生成 512x512 的随机浮点灰度图，值范围0~1 noise = np.random.rand(512, 512) plt.imshow(noise, cmap=\u0026#39;gray\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.imsave(\u0026#39;random_noise.png\u0026#39;, noise, cmap=\u0026#39;gray\u0026#39;) 完全随机的噪声：\n而 Perlin Noise 相邻点直接是有关联的，相邻点的数值上要求接近而且平滑。\n高斯白噪声 import numpy as np import matplotlib.pyplot as plt # 生成512x512的高斯白噪声，均值0.5，标准差0.1 noise = np.random.normal(loc=0.5, scale=0.1, size=(512, 512)) # 将值裁剪到0~1范围内，防止显示异常 noise = np.clip(noise, 0, 1) plt.imshow(noise, cmap=\u0026#39;gray\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.imsave(\u0026#39;gaussian_white_noise_2d.png\u0026#39;, noise, cmap=\u0026#39;gray\u0026#39;) plt.show() 由于非均匀分布，看起来会比白噪声更加柔和一点。\n高斯分布在一维上看起来会更加明显，因为有一个明显的中心带，集中了绝大多数点。\n1D Perlin Noise 如果我们需要理解 Perlin Noise 中分型相关的概念，我们需要先理解一下Fade、周期性和频率倍率的概念3。\nFade 在已知一系列点的数值的情况下，如果希望求中间的点的数值，可以通过线性插值产生折线，通过 Cosine 插值产生平滑的曲线。\n余弦插值可以用下列公式，\n$$ x = x1 + (x2-x1) * (1 - cos(\\pi \\alpha)) / 2 $$\n不同的插值方法的目的，就是在过渡处产生平滑的曲线而不是折线。除了余弦函数，还可以用三次函数、五次函数等等插值方法。\n这种把线性插值，转化为平滑插值，就叫 Fade 。\nPerlin 在改进型的噪声生成算法中采用的 Fade 函数是，\n$$ t = 6 t^5 - 15 t^4 + 10 t^3 $$\nOctaves 如果将采样频率不断翻倍，就可以获得不断减半周期的函数。由于音阶每个八度之间就是频率翻倍的关系，所以这里也叫做 Octaves 。\n将不同周期的噪声按照某种权重进行混合，就构成了 Perlin Noise 。\n通常将周期不断翻倍，同时将权重不断减半。这里有一种分型的概念。\n2D Perlin Noise Generator 算法 Ken Perlin 在他的网站上公布了 Perlin Noise 改进版的实现4。\nPerlin 噪声是一种基于网格的渐进式噪声函数，常用于生成自然感的纹理、地形等。二维版本的实现过程如下：\n1. 网格划分 将二维空间划分成一个规则的整数格点网格，每个格点都关联一个随机梯度向量（通常是单位向量，方向均匀分布）。\n2. 计算插值点的相对位置 给定采样点 $(x, y)$，先确定它所在的格点单元，即计算格点左下角的整数坐标 $(X, Y)$，\n$$ X = \\lfloor x \\rfloor, \\quad Y = \\lfloor y \\rfloor $$\n计算采样点相对于左下格点的局部坐标，\n$$ x_{rel} = x - X, \\quad y_{rel} = y - Y $$\n3. 计算格点梯度与距离向量的点积 对于这个单元的4个角（格点），\n$$ (X, Y), (X+1, Y), (X, Y+1), (X+1, Y+1) $$\n分别取出每个格点对应的梯度向量 $\\vec{g}$，计算梯度向量与采样点到该格点的距离向量 $\\vec{d}$ 的点积，\n$$ \\text{dot} = \\vec{g} \\cdot \\vec{d} $$\n4. 插值平滑 对上述4个点积结果，使用平滑插值函数（如 Ken Perlin 提出的 fade 函数）沿 x 和 y 方向进行双线性插值，\n$$ u = \\text{fade}(x_{rel}), \\quad v = \\text{fade}(y_{rel}) $$\n5. 输出噪声值 插值后的结果就是采样点 $(x,y)$ 的噪声值，通常范围大约在 $[-1, 1]$。\nPython Code 这里给出实现 2D Perlin Noise 算法的 Python 代码。\nimport numpy as np import matplotlib.pyplot as plt permutation = np.array([ 151,160,137,91,90,15, 131,13,201,95,96,53,194,233,7,225,140,36,103,30,69,142,8,99,37,240,21,10,23, 190, 6,148,247,120,234,75,0,26,197,62,94,252,219,203,117,35,11,32,57,177,33, 88,237,149,56,87,174,20,125,136,171,168, 68,175,74,165,71,134,139,48,27,166, 77,146,158,231,83,111,229,122,60,211,133,230,220,105,92,41,55,46,245,40,244, 102,143,54, 65,25,63,161, 1,216,80,73,209,76,132,187,208, 89,18,169,200,196, 135,130,116,188,159,86,164,100,109,198,173,186, 3,64,52,217,226,250,124,123, 5,202,38,147,118,126,255,82,85,212,207,206,59,227,47,16,58,17,182,189,28,42, 223,183,170,213,119,248,152, 2,44,154,163, 70,221,153,101,155,167, 43,172,9, 129,22,39,253, 19,98,108,110,79,113,224,232,178,185, 112,104,218,246,97,228, 251,34,242,193,238,210,144,12,191,179,162,241, 81,51,145,235,249,14,239,107, 49,192,214, 31,181,199,106,157,184, 84,204,176,115,121,50,45,127, 4,150,254, 138,236,205,93,222,114,67,29,24,72,243,141,128,195,78,66,215,61,156,180 ], dtype=np.uint16) p = np.tile(permutation, 2) def grad(hash:int, x:float, y:float)-\u0026gt;float: grad_vectors = np.array([ [1, 1], [-1, 1], [1, -1], [-1, -1], [1, 0], [-1, 0], [0, 1], [0, -1] ]) # 归一化梯度向量 grad_vectors = grad_vectors / np.linalg.norm(grad_vectors, axis=1)[:, None] g = grad_vectors[hash % 8] return np.dot(g, [x, y]) def lerp(t: float, a: float, b: float)-\u0026gt;float: return a + t * (b - a) def fade(t: float)-\u0026gt;float: return t * t * t * (t * (t * 6 - 15) + 10) def get_noise(x:float, y:float): X = int(np.floor(x)) \u0026amp; 255 Y = int(np.floor(y)) \u0026amp; 255 x = x % 1 y = y % 1 u = fade(x) v = fade(y) ## 这里其实只要保证hash唯一就可以了 x1 = p[p[X] + Y] x2 = p[p[X+1] + Y] x3 = p[p[X] + Y + 1] x4 = p[p[X+1] + Y + 1] ## x3 x4 ## x1 x2 ## vector 方向都是从整数点 指向 噪声采样点 return lerp(v, lerp(u, grad(x1, x, y), grad(x2, x - 1, y)), lerp(u, grad(x3, x, y - 1), grad(x4, x - 1, y - 1))) def get_perlin_noise(width=256, height=256, scale=8.0, octaves=1, persistence=0.5, lacunarity=2.0): noise_arr = np.zeros((height, width), dtype=np.float32) for i in range(height): for j in range(width): for k in range(octaves): x = (j / width) * scale * (lacunarity ** k) y = (i / height) * scale * (lacunarity ** k) noise_arr[i, j] += (persistence ** k) * get_noise(x, y) return noise_arr fig, axs = plt.subplots(2, 2, figsize=(10, 10)) for octave_count, ax in zip(range(1, 5), axs.flatten()): noise_arr = get_perlin_noise(width=256, height=256, scale=8.0, octaves=octave_count) # 可选将范围变为 0~1 noise_arr = (noise_arr - noise_arr.min()) / (noise_arr.max() - noise_arr.min()) ax.imshow(noise_arr, cmap=\u0026#39;gray\u0026#39;) ax.set_title(f\u0026#39;octaves = {octave_count}\u0026#39;, fontsize=14) ax.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.savefig(\u0026#39;perlin_noise_octaves_1_to_4.png\u0026#39;) 梯度值如何改进 使用固定梯度值而不是 Hash 完全均匀随机产生的梯度值，是避免导致方向性偏差，影响视觉自然度5。\n在原版中，梯度值是均匀分布在球面上，但是立方体并不是球面均匀的，沿着坐标轴方向会缩短，沿着对角线方向会拉长。\n这种方向上的不对称，容易导致一种零星的聚集效应：当一些彼此接近、方向几乎与坐标轴平行的梯度碰巧朝同一个方向排列时，就会在这些区域出现异常偏高的数值。\n所以 Perlin 在改进论文中建议选择：\n$$ (1,1,0),(-1,1,0),(1,-1,0),(-1,-1,0), (1,0,1),(-1,0,1),(1,0,-1),(-1,0,-1), (0,1,1),(0,-1,1),(0,1,-1),(0,-1,-1) $$\n同时为了避免除以 12 的开销，他将梯度方向补齐到 16 个，额外添加了 $(1,1,0),(-1,1,0),(0,-1,1),(0,-1,-1)$。\n本文参考了这个实现方式，使用的是平面8个方向的梯度，并且都进行了长度的归一化。\n如果是一维的 Perlin Noise，可以不进行归一化来增加波动。一维的 Perlin Noise 可以视作在二维的 Perlin Noise 沿着晶格画一条线，此时不在线上的晶格的权重都是0，和一维的 Perlin Noise 没有区别。在这种情况下，梯度值在水平方向上的投影就不是唯一的1， 斜边的投影大小是 $ \\frac{\\sqrt{2}}{2} $。\nFade 函数的改进 Perlin5 在论文中提出的改进就是替换 Fade 函数为二阶平滑的函数，也就是我上面所用的函数。\n原因是，如果二阶导数不是平滑的话，当它用于做表面替换的时候，能够看出非常明显的方块样式。\n所以最好遵循以下原则：\n在 0 和 1 的时候，导数应该为 0，使得其尽可能平滑过渡。甚至高阶导也可以为 0。 $ f(0) = 0 $ $ f(1) = 1 $ 应用举例 Python Noise 库 实际使用过程中，我们完全不需要编写 Perlin Noise 的代码。而是使用 Python Noise 库就可以直接生成 Perlin Noise 。\nimport numpy as np import matplotlib.pyplot as plt from noise import pnoise2 width, height = 512, 512 scale = 64.0 # 控制噪声“拉伸”程度，数值越大变化越缓慢 octaves = 6 persistence = 0.5 lacunarity = 2.0 noise = np.zeros((height, width)) for y in range(height): for x in range(width): nx = x / scale ny = y / scale noise[y][x] = pnoise2(nx, ny, octaves=octaves, persistence=persistence, lacunarity=lacunarity, repeatx=1024, repeaty=1024, base=0) # Perlin噪声默认范围大致在[-1,1]，归一化到[0,1] noise = (noise - noise.min()) / (noise.max() - noise.min()) plt.imshow(noise, cmap=\u0026#39;gray\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.imsave(\u0026#39;perlin_noise_2d_lib.png\u0026#39;, noise, cmap=\u0026#39;gray\u0026#39;) plt.show() 由于进行了优化，它的生成速度非常快：\n云层 用 Perlin Noise 模拟简单云层纹理。\n模拟云层边缘的消散效果\n模拟中心的高亮，因此大于阈值部分不动，只在某个范围内进行下列的操作。\n$$ \\text{Intensity} = max(\\text{Intensity} - 40, 0) $$\nimport numpy as np from PIL import Image # 读灰度图，保持 0~255 整数 img = Image.open(\u0026#39;perlin_noise_2d_lib.png\u0026#39;).convert(\u0026#39;L\u0026#39;) arr = np.array(img).astype(np.int32) # 0~255 height, width = arr.shape # 创建RGB图，纯蓝底 (R,G,B) = (0,0,255) rgb_img = np.zeros((height, width, 3), dtype=np.uint8) for y in range(height): for x in range(width): r, g, b = 0, 0, 255 cloud_intensity = arr[y, x] # 0~255 cloud_intensity = cloud_intensity - 30 if cloud_intensity \u0026lt; 100: cloud_intensity = max(cloud_intensity - 40, 0) # 线性混合，cloud_intensity 代表白云强度 (0~255) # 先计算权重：cloud_intensity / 255 w = cloud_intensity / 255 r = int(r * (1 - w) + w * 255) g = int(g * (1 - w) + w * 255) b = int(b * (1 - w) + w * 255) rgb_img[y, x, 0] = r rgb_img[y, x, 1] = g rgb_img[y, x, 2] = b # 直接保存uint8数组 im = Image.fromarray(rgb_img) im.save(\u0026#39;perlin_cloud.png\u0026#39;) 云层效果如图：\nPerlin, K. (1985). An image synthesizer. ACM Siggraph Computer Graphics, 19(3), 287-296.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPerlin Noise wiki, https://en.wikipedia.org/wiki/Perlin_noise\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nRoger Eastman. (2019). CMSC425.01 Spring 2019 Lecture 20: Perlin noise I. University of Maryland. https://www.cs.umd.edu/class/spring2019/cmsc425/handouts/CMSC425Day20.pdf\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKen Perlin. (2022). Improved Noise reference implementation. https://mrl.cs.nyu.edu/~perlin/noise/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPerlin, K. (2002, July). Improving noise. In Proceedings of the 29th annual conference on Computer graphics and interactive techniques (pp. 681-682).\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://cronrpc.github.io/zh/posts/perlin-noise-generator/","summary":"\u003ch2 id=\"perlin-noise-介绍\"\u003ePerlin Noise 介绍\u003c/h2\u003e\n\u003cp\u003ePerlin 噪声（Perlin Noise）是由 Ken Perlin 在 1983 年为电影《Tron》开发的一种平滑伪随机噪声算法\u003csup id=\"fnref:1\"\u003e\u003ca href=\"#fn:1\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e1\u003c/a\u003e\u003c/sup\u003e。它能够生成具有自然纹理的随机模式，广泛用于计算机图形学中模拟云彩、地形、火焰、木纹、水流等自然现象\u003csup id=\"fnref:2\"\u003e\u003ca href=\"#fn:2\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e2\u003c/a\u003e\u003c/sup\u003e。\u003c/p\u003e\n\u003cp\u003e与普通白噪声不同，Perlin 噪声具有空间相关性：相邻采样点的值变化平滑，没有突兀的跳变。这种平滑特性使得它生成的纹理更像自然界的连续变化。\u003c/p\u003e","title":"Perlin Noise Generator"},{"content":"本文仅聚焦于如下几个问题：\n从三角级数展开，过渡到欧拉形式的傅里叶变换 什么是离散傅里叶变换 什么是2D傅里叶变换 从2D傅里叶变换，解释到2D离散傅里叶变换 如何对图像进行2D傅里叶变换 2D傅里叶变换的周期性问题 从2D傅里叶变换的周期性理解傅里叶2D频谱图的中心化 傅里叶级数 傅里叶级数是一种数学工具，它表示一个周期函数为一组正弦和余弦函数的无穷和。\n三角级数展开 傅里叶变换最初是基于三角级数展开，即周期函数可以表示为一系列正弦和余弦函数的线性组合：\n$$ f(t) = a_0 + \\sum_{n=1}^{\\infty} a_n \\cos(n\\omega_0 t) + b_n \\sin(n\\omega_0 t) $$\n其中 $\\omega_0 = \\frac{2\\pi}{T}$ 是基本频率。\n复指数形式 利用欧拉公式：\n$$ \\cos(x) = \\frac{e^{ix} + e^{-ix}}{2}, \\quad \\sin(x) = \\frac{e^{ix} - e^{-ix}}{2i} $$\n可以将傅里叶级数改写为复指数形式：\n$$ f(t) = \\sum_{n=-\\infty}^{\\infty} c_n e^{in\\omega_0 t} $$\n其中 $c_n$ 是复数系数，封装了正弦和余弦部分的信息。欧拉形式的傅里叶表示更对称、更易于处理，也为后续推广到连续和多维情况提供了基础。\n在这里，$n$的取值范围变成了$-\\infty$到$\\infty$。\n离散傅里叶变换 DFT 离散傅里叶变换（Discrete Fourier Transform，简称 DFT）是傅里叶分析的一个重要分支，它的作用是将离散的有限长度信号（通常是数字信号）从时间域/空间域转换到频率域，表示成一组复数频率分量的叠加。\n实际中我们处理的是有限、离散的数据。离散傅里叶变换（DFT）定义如下：\n$$ X[k] = \\sum_{n=0}^{N-1} x[n] \\cdot e^{-i \\frac{2\\pi}{N}kn}, \\quad k = 0, 1, \\dots, N-1 $$\n对应的逆变换为：\n$$ x[n] = \\frac{1}{N} \\sum_{k=0}^{N-1} X[k] \\cdot e^{i \\frac{2\\pi}{N}kn} $$\nDFT 把时间域信号 $x[n]$ 映射到频域 $X[k]$，每个 $X[k]$ 对应一个频率分量的幅度和相位。\n负频率、周期重排 离散傅里叶变换中，可以有负频率。\n虽然 DFT 的索引 $k$ 是非负整数，但傅里叶频率具有模 $N$ 的周期性。\n也就是说：\n$$ e^{-j \\frac{2\\pi}{N} k n} = e^{-j \\frac{2\\pi}{N} (k + mN) n}, \\quad \\forall m \\in \\mathbb{Z} $$\n因此，频率 $k = N - 1$ 实际上等价于频率 $-1$，频率 $k = N - 2$ 等价于 $-2$，以此类推。\n我们可以将频率索引重新解释为从负频率到正频率：\n$$ k = -\\frac{N}{2}, \\dots, -1, 0, 1, \\dots, \\frac{N}{2} - 1 \\quad (\\text{当 } N \\text{ 为偶数时}) $$\n这种方式可以通过频谱的中心化重排，使得结果更符合频率对称直觉。\n在后面的对图像的2D傅里叶变换后，频谱图通过中心化重排后，将低频区域全部变换到中央。\n2D傅里叶变换 傅里叶变换可以从将原本的1D形式，扩展到2D形式。\n什么是2D傅里叶变换 连续2D傅里叶变换的定义如下，对于一个连续函数 $f(x, y)$：\n$$ F(u, v) = \\iint_{-\\infty}^{\\infty} f(x, y) \\cdot e^{-i2\\pi (ux + vy)} , dx,dy $$\n其逆变换为：\n$$ f(x, y) = \\iint_{-\\infty}^{\\infty} F(u, v) \\cdot e^{i2\\pi (ux + vy)} , du,dv $$\n其中 $(x, y)$ 是空间域坐标，$(u, v)$ 是频率域坐标。变换结果 $F(u, v)$ 描述了信号中每个频率分量的幅值和相位。\n2D 离散傅里叶变换 离散情况下，对于一个 $M \\times N$ 的二维离散函数 $f[m, n]$，其二维离散傅里叶变换（2D DFT）定义为：\n$$ F[k, l] = \\sum_{m=0}^{M-1} \\sum_{n=0}^{N-1} f[m, n] \\cdot e^{-i 2\\pi \\left( \\frac{km}{M} + \\frac{ln}{N} \\right)} $$\n其逆变换为：\n$$ f[m, n] = \\frac{1}{MN} \\sum_{k=0}^{M-1} \\sum_{l=0}^{N-1} F[k, l] \\cdot e^{i 2\\pi \\left( \\frac{km}{M} + \\frac{ln}{N} \\right)} $$\n2D傅里叶变换的周期性 类似于1D DFT，2D DFT 也具有周期性：\n$$ F[k + M, l] = F[k, l], \\quad F[k, l + N] = F[k, l] $$\n这意味着频谱在两个方向（水平和垂直）上都是周期性的。\nDFT 中的频率索引 $k$ 和 $l$ 取值范围是 $0$ 到 $M-1$ 和 $N-1$，但这些索引并不是单纯的“正频率”，它们是模周期的。\n因为周期是 $M$ 和 $N$，所以后半部分可以看作对应的负频率分量。具体来说，当索引 $k \u0026gt; \\frac{M}{2}$ 时，实际频率等价于 $k - M$ 对应的负频率；同理，当索引 $l \u0026gt; \\frac{N}{2}$ 时，频率等价于 $l - N$ 对应的负频率。这样，频率索引的范围在 $[0, M-1]$ 和 $[0, N-1]$ 上循环，形成正负频率对称的结构。\n如何对图像进行2D傅里叶变换 Python 中可以使用 numpy 或 opencv 等库方便地进行 2D 傅里叶变换。例如，使用 NumPy：\nimport numpy as np import matplotlib.pyplot as plt from PIL import Image # 加载图像并转换为灰度 img = Image.open(\u0026#39;doge.jpg\u0026#39;).convert(\u0026#39;L\u0026#39;) f = np.array(img) # 计算2D傅里叶变换 F = np.fft.fft2(f) # 幅度谱与相位谱 magnitude_spectrum = np.abs(F) phase_spectrum = np.angle(F) log_magnitude = np.log(1 + magnitude_spectrum) # 创建子图 fig, axs = plt.subplots(1, 3, figsize=(15, 5)) # 原始图像 axs[0].imshow(f, cmap=\u0026#39;gray\u0026#39;) axs[0].set_title(\u0026#39;Original Image\u0026#39;) axs[0].axis(\u0026#39;off\u0026#39;) # 幅度谱 axs[1].imshow(log_magnitude, cmap=\u0026#39;gray\u0026#39;) axs[1].set_title(\u0026#39;Magnitude Spectrum (log)\u0026#39;) axs[1].axis(\u0026#39;off\u0026#39;) # 相位谱 im = axs[2].imshow(phase_spectrum, cmap=\u0026#39;gray\u0026#39;) axs[2].set_title(\u0026#39;Phase Spectrum\u0026#39;) axs[2].axis(\u0026#39;off\u0026#39;) # 添加 colorbar 到相位谱 fig.colorbar(im, ax=axs[2], shrink=0.7) plt.tight_layout() plt.show() 运行后可以看到幅度谱和相位谱，这里需要注意的一点在于，\n逆变换还原图像（频率+相位） 傅里叶变换的结果是复数，包含了幅度（Magnitude）和相位（Phase）信息。只保留其中之一就不能完整还原图像。\n还原图像的方式如下：\nimport numpy as np import matplotlib.pyplot as plt from PIL import Image # 加载图像并转换为灰度 img = Image.open(\u0026#39;doge.jpg\u0026#39;).convert(\u0026#39;L\u0026#39;) f = np.array(img) # 计算2D傅里叶变换 F = np.fft.fft2(f) # 进行逆傅里叶变换 recovered = np.fft.ifft2(F) recovered_real = np.real(recovered) plt.imshow(recovered_real, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Recovered Image from IFFT\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.show() 逆变换后应该和原图一样。\n频谱图中心化 为了更清晰地观察频率分布，我们通常对频谱进行中心化，使低频位于中心，高频分布在周围。\n中心化操作可以使用 np.fft.fftshift：\nimport cv2 import numpy as np import matplotlib.pyplot as plt img = cv2.imread(\u0026#39;doge.jpg\u0026#39;, cv2.IMREAD_GRAYSCALE) f = np.fft.fft2(img) fshift = np.fft.fftshift(f) magnitude_spectrum = 20 * np.log(np.abs(fshift) + 1) plt.figure(figsize=(12, 6)) plt.subplot(1, 2, 1) plt.title(\u0026#39;Original Image\u0026#39;) plt.imshow(img, cmap=\u0026#39;gray\u0026#39;) plt.subplot(1, 2, 2) plt.title(\u0026#39;Magnitude Spectrum\u0026#39;) plt.imshow(magnitude_spectrum, cmap=\u0026#39;gray\u0026#39;) plt.show() 此时频谱图将低频成分移到了中心，更易于观察纹理和方向性等信息。\n中心大致可以表示轮廓信息，而细节纹理是高频信息位于边缘。\n","permalink":"https://cronrpc.github.io/zh/posts/2d-fourier-transform/","summary":"\u003cp\u003e本文仅聚焦于如下几个问题：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e从三角级数展开，过渡到欧拉形式的傅里叶变换\u003c/li\u003e\n\u003cli\u003e什么是离散傅里叶变换\u003c/li\u003e\n\u003cli\u003e什么是2D傅里叶变换\u003c/li\u003e\n\u003cli\u003e从2D傅里叶变换，解释到2D离散傅里叶变换\u003c/li\u003e\n\u003cli\u003e如何对图像进行2D傅里叶变换\u003c/li\u003e\n\u003cli\u003e2D傅里叶变换的周期性问题\u003c/li\u003e\n\u003cli\u003e从2D傅里叶变换的周期性理解傅里叶2D频谱图的中心化\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"傅里叶级数\"\u003e傅里叶级数\u003c/h2\u003e\n\u003cp\u003e傅里叶级数是一种数学工具，它表示一个周期函数为一组正弦和余弦函数的无穷和。\u003c/p\u003e","title":"2D Fourier Transform"}]